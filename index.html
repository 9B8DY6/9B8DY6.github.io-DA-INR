<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>[MICCAI 2025] Dynamic-Aware Spatio-temporal Representation Learning for Dynamic MRI Reconstruction</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">DA-INR: Dynamic-Aware Spatio-temporal Representation Learning for Dynamic MRI Reconstruction</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://github.com/9B8DY6" target="_blank">Dayoung Baik</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://sites.google.com/view/jaejunyoo" target="_blank">Jaejun Yoo</a><sup>&dagger;</sup><sup>1</sup>,
                  <!-- <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Third Author</a> -->
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                      <sup>1</sup>Ulsan National Institute of Science and Technology (UNIST)<br>
                      <span class="eql-cntrb"><small><sup>&dagger;</sup>Corresponding authors</small></span><br>
                      <span><b>MICCAI 2025</b></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://papers.miccai.org/miccai-2025/paper/5140_paper.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/9B8DY6/DA_INR" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://www.arxiv.org/abs/2501.09049" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Arxiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Dynamic MRI reconstruction, one of inverse problems, has seen a surge by the use of deep learning techniques. Especially, the practical difficulty of obtaining ground truth data has led to the emergence of unsupervised learning approaches. A recent promising method among them is implicit neural representation (INR), which defines the data as a continuous function that maps coordinate values to the corresponding signal values. This allows for filling in missing information only with incomplete measurements and solving the inverse problem effectively. Nevertheless, previous works incorporating this method have faced drawbacks such as long optimization time and the need for extensive hyperparameter tuning. To address these issues, we propose Dynamic-Aware INR (DA-INR), an INR-based model for dynamic MRI reconstruction that captures the spatial and temporal continuity of dynamic MRI data in the image domain and explicitly incorporates the temporal redundancy of the data into the model structure. As a result, DA-INR outperforms other models in reconstruction quality even at extreme undersampling ratios while significantly reducing optimization time and requiring minimal hyperparameter tuning.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Overall Pipeline</h2>
        <figure class="image">
          <img src="static/images/ours_methodv2.png" alt="MY ALT TEXT"/>
        </figure>
        <div class="content has-text-justified">
          <p>
             <b>Overall pipeline of DA-INR.</b> A deformation network \( \Psi_t \) takes a spatio-temporal coordinate \( (x, y, t) \) as input to output deformation field \( \Delta \mathbf{x} = (\Delta x, \Delta y) \) based on a canonical space. A pretrained feature extractor extracts features from an undersampled data in the image domain. A canonical network \( \Psi_x \) takes the deformed coordinate \( \mathbf{x}' \) and the features \( \mathbf{f}' \) to predict \( t^{\text{th}} \) frame in the image domain, \( d_\theta \). These two models are optimized by L1 loss computation in the frequency domain with Non-uniform Fast Fourier Transform (NuFFT). "Sampling" means upscaling the coordinates or the features by nearest-neighborhood or bilinear interpolation. F.E and H.E mean Frequency Encoding and Hash Encoding.
          </p>
      </div>
    </div>
  </div>
</section>

<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Encoding Temporal Redundancy</h2>
        <figure class="image">
          <img src="static/images/encoding_temporal_redun.png" style="display: block; margin: 0 auto;max-width: 95%; height: auto;" alt="MY ALT TEXT"/>
        </figure>
        <div class="content has-text-justified">
          <p>
             <b>Encoding Temporal Redundancy in DA-INR.</b> In DA-INR, the cells of the image in the canonical space plays a regularization role to those of all other frames. The purplish lines between frame-by-frame indicate that DA-INR is continuous in time, but does not merely represent dynamic MRI data as 3D mass like existing methods.
          </p>
      </div>
    </div>
  </div>
</section>

<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Qualitative Results</h2>

        <!-- ðŸ”¹ ì²« ë²ˆì§¸ í–‰ ì†Œì£¼ì œ -->
        <!-- <div class="content has-text-centered mb-4">
          <h3 class="title is-4">Results in \( (y-x) \) domain</h3>
        </div> -->

        <figure class="image">
          <img src="static/images/cardiac_recon.png" style="display: block; margin: 0 auto;max-width: 88%; height: auto;" alt="MY ALT TEXT"/>
          <figcaption class="has-text-centered mt-2">
            <b>Qualitative Results in \( (y-x) \) domain</b> of \(AF=9.8\) in cardiac cine data reconstruction at diastole and systole.
          </figcaption>
        </figure>

        <!-- ðŸ”¹ ë‘ ë²ˆì§¸ í–‰ ì†Œì£¼ì œ -->
        <!-- <div class="content has-text-centered mt-6 mb-4">
          <h3 class="title is-4">Results in \( (x-t) \) domain</h3>
        </div> -->

        <figure class="image">
          <img src="static/images/cardiac_recon_temp.png" style="display: block; margin: 0 auto;max-width: 88%; height: auto;" alt="Reconstruction 2">
          <figcaption class="has-text-centered mt-2">
            <b>Qualitative Results in \( (x-t) \) domain</b> of cardiac cine data reconstruction in various \(AF\)s.
          </figcaption>
        </figure>
        
        
        <figure class="image">
          <img src="static/images/liver.png" style="display: block; margin: 0 auto;max-width: 90%; height: auto;" alt="Reconstruction 33">
          <figcaption class="has-text-centered mt-2">
            <b>Qualitative results of DCE liver data</b> reconstruction with an undersampling ratio of 34 spokes per frame \( (AF=11.3) \). We visualize reconstruction at different contrast phases (left), and compare signal intensity flow for aorta (AO) and portal vein (PV) ROI (right).
          </figcaption>
        </figure>
        <div class="content has-text-justified">
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <!-- âœ… ëŒ€ì£¼ì œ ì œëª© -->
    <div class="content has-text-centered mb-6">
      <h2 class="title is-3">Spatio-temporal Interpolation Ability of DA-INR</h2>
      <!-- <p class="subtitle is-5">Spatio-temporal Interpolation Ability of DA-INR</p> -->
    </div>

    <!-- ðŸ”¹ ì²« ë²ˆì§¸ í–‰ ì†Œì£¼ì œ -->
    <div class="content has-text-centered mb-4">
      <h3 class="title is-4">Spatial Interpolation</h3>
    </div>

    <!-- <div class="columns">
      <div class="column is-half">
        <figure class="image">
          <img src="static/images/spatial_interpolation_method.png" alt="Image 1">
          <figcaption class="has-text-centered mt-2">Spatial Interpolation Framework.</figcaption>
        </figure>
      </div>
      <div class="column is-half">
        <figure class="image">
          <img src="static/images/spa_int_result.png" alt="Image 2">
          <figcaption class="has-text-centered mt-2">Qualitative results in spatial interpolation \( (\times 1.2, \times 1.5, \times 2) \) task at \(AF=9.8\).</figcaption>
        </figure>
      </div>
    </div> -->
    <figure class="image">
      <img src="static/images/spa_int_result.png" style="display: block; margin: 0 auto;max-width: 86%; height: auto;" alt="MY ALT TEXT"/>
      <figcaption class="has-text-centered mt-2">
        Qualitative results in spatial interpolation \( (\times 1.2, \times 1.5, \times 2) \) task of cardiac cine data at \(AF=9.8\).
      </figcaption>
    </figure>

    <!-- ðŸ”¹ ë‘ ë²ˆì§¸ í–‰ ì†Œì£¼ì œ -->
    <div class="content has-text-centered mt-6 mb-4">
      <h3 class="title is-4">Temporal Interpolation</h3>
    </div>

    <!-- <div class="columns">
      <div class="column is-half">
        <figure class="image">
          <img src="static/images/temporal_interpolation_method.png" alt="Image 3">
          <figcaption class="has-text-centered mt-2">Temporal Interpolation Framework.</figcaption>
        </figure>
      </div>
      <div class="column is-half">
        <figure class="image">
          <img src="static/images/temp_int_result.png" alt="Image 4">
          <figcaption class="has-text-centered mt-2">Comprehensive results in temporal interpolation \( (\times 2, \times 3) \) task. (a), (b) Temporal interpolation results at \(AF=6.1\) for \( (\times2) \) and \( (\times3) \), respectively.</figcaption>
        </figure>
      </div>
    </div> -->
    <figure class="image">
      <img src="static/images/temp_int_result.png" style="display: block; margin: 0 auto;max-width: 88%; height: auto;" alt="MY ALT TEXT"/>
      <figcaption class="has-text-centered mt-2">
        Comprehensive results in temporal interpolation \( (\times 2, \times 3) \) task of cardiac cine data. (a), (b) Temporal interpolation results at \(AF=6.1\) for \( (\times2) \) and \( (\times3) \), respectively. (c) The visual comparison of each method in the \( (x-t) \) domain.
      </figcaption>
    </figure>


  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <!-- âœ… ëŒ€ì£¼ì œ ì œëª© -->
    <div class="content has-text-centered mb-6">
      <h2 class="title is-3">Ablation Study of Pretrained Feature Extractor Types</h2>
    </div>

    <!-- ðŸ”¹ Table -->
    <div class="table-container" style="overflow-x: auto;">
      <table class="table is-bordered is-striped is-hoverable is-fullwidth is-size-6 has-text-centered">
        <thead>
          <tr>
            <th>Feature Extractor</th>
            <th>PSNR (dB)</th>
            <th>SSIM</th>
            <th>GPU Memory Usage (GB)</th>
            <th>Runtime (sec)</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>w/o Encoder</td>
            <td>29.59</td>
            <td>0.8807</td>
            <td>1.9</td>
            <td>1332.80</td>
          </tr>
          <tr>
            <td>EDSR [1]</td>
            <td>29.53</td>
            <td>0.8790</td>
            <td>3.5</td>
            <td>2826.45</td>
          </tr>
          <tr>
            <td>RDN [2]</td>
            <td>29.28</td>
            <td>0.8750</td>
            <td>12.0</td>
            <td>6024.91</td>
          </tr>
          <tr>
            <td>SwinIR [3]</td>
            <td>29.34</td>
            <td>0.8816</td>
            <td>18.3</td>
            <td>5889.91</td>
          </tr>
          <tr>
            <td>MDSR [4] (Ours)</td>
            <td>30.13</td>
            <td>0.8835</td>
            <td>3.5</td>
            <td>1445.50</td>
          </tr>
        </tbody>
      </table>
    </div>

    <!-- ðŸ”¹ References -->
    <div class="content mt-5" style="font-size: 0.9rem;">
      <strong>References</strong>
      <ol style="margin-left: 1.2em; margin-top: 0.5em;">
        <li>
          Bee Lim, Sanghyun Son, Heewon Kim, Seungjun Nah, and Kyoung Mu Lee. 
          <i>Enhanced deep residual networks for single image super-resolution</i>. 
          CoRR, abs/1707.02921, 2017.
        </li>
        <li>
          Yulun Zhang, Yapeng Tian, Yu Kong, Bineng Zhong, and Yun Fu. 
          <i>Residual dense network for image super-resolution</i>. 
          CoRR, abs/1802.08797, 2018.
        </li>
        <li>
          Jingyun Liang, Jiezhang Cao, Guolei Sun, Kai Zhang, Luc Van Gool, and Radu Timofte. 
          <i>SwinIR: Image restoration using swin transformer</i>. 
          In <i>Proceedings of the IEEE/CVF International Conference on Computer Vision</i>, pages 1833â€“1844, 2021.
        </li>
        <li>
          Shangqi Gao and Xiahai Zhuang. Multi-scale deep neural networks for real image super-resolution. CoRR, abs/1904.10698, 2019.
        </li>
      </ol>
    </div>

  </div>
</section>


<!-- Image carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item"> -->
        <!-- Your image here -->
        <!-- <img src="static/images/carousel1.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          First image description.
        </h2>
      </div>
      <div class="item"> -->
        <!-- Your image here -->
        <!-- <img src="static/images/carousel2.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Second image description. -->
        <!-- </h2>
      </div> -->
      <!-- <div class="item"> -->
        <!-- Your image here -->
        <!-- <img src="static/images/carousel3.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Third image description.
       </h2>
     </div>
     <div class="item"> -->
      <!-- Your image here -->
      <!-- <img src="static/images/carousel4.jpg" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Fourth image description.
      </h2>
    </div>
  </div>
</div>
</div>
</section> -->
<!-- End image carousel -->




<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container"> -->
      <!-- Paper video. -->
      <!-- <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video"> -->
            <!-- Youtube embed code here -->
            <!-- <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%"> -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div> -->
        <!-- <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%"> -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\ -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@InProceedings{BaiDay_DynamicAware_MICCAI2025,
        author = { Baik, Dayoung AND Yoo, Jaejun},
        title = { { Dynamic-Aware Spatio-temporal Representation Learning for Dynamic MRI Reconstruction } },
        booktitle = {proceedings of Medical Image Computing and Computer Assisted Intervention -- MICCAI 2025},
        year = {2025},
        publisher = {Springer Nature Switzerland},
        volume = {LNCS 15963},
        month = {September},
        page = {174 -- 184}
}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from theÂ <a href="https://nerfies.github.io" target="_blank">Nerfies</a>Â project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
